{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a ref=\"C:/Users/josep/Snowman/Reforçat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" ref=\"C:/Users/josep/Snowman/Reforçat.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o2j3RSpxf_o4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\anaconda3\\envs\\python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\josep\\anaconda3\\envs\\python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\josep\\anaconda3\\envs\\python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import glob\n",
    "\n",
    "n=8\n",
    "m=16\n",
    "\n",
    "Mov=[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/josep/Snowman/Dades/facils/\"\n",
    "\n",
    "files=glob.glob(path+\"*.txt\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intern code:\n",
    "\n",
    "- 0 : out of grid and wall (x and #)\n",
    "- 1 : small ball\n",
    "- 2 : medium ball\n",
    "- 3 : small ball on top of a medium ball\n",
    "- 4 : large ball\n",
    "- 5 : small ball on top of a large ball\n",
    "- 6 : medium ball on top of a large ball\n",
    "- 7 : small ball on top of a medium ball on top of a large ball\n",
    "- 8 : grass (')\n",
    "- 9 : snow (.)\n",
    "- 10: character with snow on the floor (p)\n",
    "- 11: character with grass on the floor (q)\n",
    "\n",
    "\n",
    "Reconpenses\n",
    "- 0 moure's sense apretar \n",
    "- 0 moure's apretant bola petita\n",
    "- 0 moure's apretant bola mitjana\n",
    "- 0 moure's apretant bola grossa\n",
    "- 100 col.locar bola mitjana sobre bola grossa\n",
    "- 500 col.locar bola petita sobre boles mitjnes i grosses\n",
    "- -1 Passar un instant \n",
    "\n",
    "Accions prohibides (-100 punts)\n",
    "- sortir de la quadricula (trepitjar pared)\n",
    "- fer sortir bola de la quadricula (trepitjar pared la bola)\n",
    "- fer 2 boles grans\n",
    "- fer dos boles mitjanes si ja tenim bola gran\n",
    "\n",
    "\n",
    "Maxim episodi=50 jugades, fins acció prohibida o col.locar tres boles be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=-20\n",
    "tonto=-20\n",
    "cami=-1\n",
    "camir=0\n",
    "cim=5\n",
    "cimbo=20\n",
    "convertir=2\n",
    "bingo=50\n",
    "\n",
    "actions=[ \n",
    "        # pared                   bola petita          bola mitjana         bola pet s mit            bola grossa           bola pet s gr         bola mit s gr             tres boles            herba                   neu              \n",
    "    [[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error]], #pared\n",
    "    [[None,None,None,error],[None,None,None,tonto],['pq',11,3,cim]       ,[None,None,None,tonto],['pq',11,5,cim]       ,[None,None,None,tonto],['pq',11,7,bingo]     ,[None,None,None,tonto],['pq',11,1,camir]     ,['pq',11,2,convertir]],  #bola petita\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],['pq',11,6,cimbo]     ,[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],['pq',11,2,camir]      ,['pq',11,4,convertir]],  #bola mitjana\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,2,1,-cim]       ,[None,2,1,-cim]],        #bola pet s mit\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],['pq',11,4,cami]      ,['pq',11,4,cami]],       #bola gran\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,4,1,-cim]       ,[None,4,2,-cim]],        #bola pet s gr\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,4,2,-cimbo]     ,[None,4,4,-cimbo]],      #bola mitj s gr\n",
    "    [[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error]], #tres boles\n",
    "    [['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,tonto]  ,['pq',11,None,cami]   ,['pq',11,None,cami]],    #herba\n",
    "    [['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,tonto]  ,['pq',10,None,cami]   ,['pq',10,None,cami]]     #neu\n",
    "] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ree=\"x#'.pq1234567\"\n",
    "reem=[0,0,8,9,10,11,1,2,3,4,5,6,7]\n",
    "def lleguir_tauler(nom,n=n,m=m):\n",
    "    f = open(nom, \"r\")\n",
    "    tauler=np.zeros((n,m),dtype=int)\n",
    "    for row,linea in enumerate(f):\n",
    "        linea=linea.rstrip('\\n\\r\\t')\n",
    "        for column,car in enumerate(linea):\n",
    "            res = ree.find(car)\n",
    "            tauler[row,column]=reem[res]\n",
    "    f.close()\n",
    "    return np.array(tauler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_step(t,reward,row,column,sega,segb,segaa,segbb):\n",
    "    bonus=2\n",
    "    if reward==cami:\n",
    "        ball=[1,2]\n",
    "        distact=distancia(t,row,column,ball)\n",
    "        distnou=distancia(t,sega,segb,ball)\n",
    "        if distnou<distact:\n",
    "            reward=cami+bonus\n",
    "    if reward==camir:\n",
    "        if t[sega,segb]==1:\n",
    "            ball=[2,6]\n",
    "        elif t[sega,segb]==2:\n",
    "            ball=[4]\n",
    "        else:\n",
    "            ball=[]\n",
    "        distact=distancia(t,row,column,ball)\n",
    "        distnou=distancia(t,sega,segb,ball)\n",
    "        if distnou<distact:\n",
    "            reward=camir+bonus\n",
    "    if reward==convertir:\n",
    "        if t[sega,segb]==2:\n",
    "            res = np.isin(t,[4,5,6])\n",
    "            res = np.array(np.where(res))\n",
    "            if np.size(res)!=0:\n",
    "                reward=error\n",
    "        else:\n",
    "            res = np.isin(t,[2,3,6])\n",
    "            res = np.array(np.where(res))\n",
    "            res2= np.isin(t,[4,5,6])\n",
    "            res2= np.array(np.where(res2))\n",
    "            if np.size(res)>0:\n",
    "                if res.shape[1]>=2 or (res.shape[1]==1 and res2.shape[1]>=1):\n",
    "                    reward=error\n",
    "    \n",
    "        \n",
    "    return reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(t,r,c,ball):\n",
    "    dist=500\n",
    "    for b in ball:\n",
    "        res = np.array(np.where(t == b))\n",
    "        if np.size(res)!=0:\n",
    "            for j in range(res.shape[1]):\n",
    "                if abs(r-res[0][j])+abs(c-res[1][j])<dist:\n",
    "                    dist=abs(r-res[0][j])+abs(c-res[1][j])\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "def step(t,action): # 0 dreta, 1 baix, 2 esquerra, 3 dalt\n",
    "    snow=True\n",
    "    res = np.array(np.where(t == 10))\n",
    "    if np.size(res)==0: \n",
    "        snow=False\n",
    "        res = np.array(np.where(t == 11))\n",
    "    a=res[0][0]\n",
    "    b=res[1][0]\n",
    "    \n",
    "    inc=[[0,1,0,-1],[1,0,-1,0]]\n",
    "    seg=[a+inc[0][action],b+inc[1][action]]\n",
    "    seg2=[a+2*inc[0][action],b+2*inc[1][action]]\n",
    "\n",
    "    Mov[action]=Mov[action]+1\n",
    "    if seg2[0]<0 or seg2[0]>=8 or seg2[1]<0 or seg2[1]>=16:\n",
    "        aux=0\n",
    "    else:\n",
    "        aux=t[seg2[0],seg2[1]]\n",
    "\n",
    "    mact=actions[t[seg[0],seg[1]]][aux]\n",
    "    reward=mact[3]\n",
    "    mact=mact[:3]\n",
    "    for i,aux in enumerate(mact):\n",
    "        if aux!=None:\n",
    "            if aux=='pq':\n",
    "                if snow:\n",
    "                    f=9\n",
    "                else:\n",
    "                    f=8\n",
    "            else:\n",
    "                f=int(aux)\n",
    "\n",
    "            if i==0:\n",
    "                t[a,b]=f\n",
    "            elif i==1:\n",
    "                t[seg[0],seg[1]]=f\n",
    "            else:\n",
    "                t[seg2[0],seg2[1]]=f\n",
    "    \n",
    "    if reward==bingo or reward<=tonto:\n",
    "        done=True\n",
    "    else:\n",
    "        done=False\n",
    "\n",
    "    return (t,reward,done,a,b,seg[0],seg[1],seg2[0],seg2[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arreglar_taula(t):\n",
    "    t2=t.copy()\n",
    "    res = np.array(np.where(t2 == 11))\n",
    "    if np.size(res)!=0:\n",
    "        t2[res[0][0],res[1][0]]=10\n",
    "    return t2/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rfaXj3ihf_pJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "from random import choices\n",
    "\n",
    "\n",
    "\n",
    "def play_one_step(t, model, loss_fn,antact=-3,antreward=-1,iteration=1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        left_proba = tf.squeeze(model(arreglar_taula(t)[np.newaxis]))\n",
    "    \n",
    "        r=np.random.uniform()\n",
    "        rati=max((1000-iteration)/1000*0.5,0.10)\n",
    "        if r>rati:\n",
    "            action = choices(population=range(4), k=1, weights=left_proba)\n",
    "        else:\n",
    "            action = choices(population=range(4), k=1)\n",
    "       \n",
    "        y_target = np.eye(4)[action[0]]\n",
    "        loss = tf.reduce_mean(loss_fn(y_target, left_proba))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    t, reward, done, a, b, sega, segb, segaa, segbb= step(t,action[0])\n",
    "    reward=mod_step(t,reward,a,b,sega,segb,segaa,segbb)\n",
    "    return t, action[0],reward, done, grads,rati\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IgF5UpXKf_pK"
   },
   "outputs": [],
   "source": [
    "def play_multiple_episodes(n_episodes, n_max_steps, model, loss_fn,iteration):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "\n",
    "    \n",
    "    nom=files[iteration % len(files)]\n",
    "    tauler=lleguir_tauler(nom,n=n,m=m)\n",
    "    for i in range(4):\n",
    "        maxim=-1000000\n",
    "        for episode in range(n_episodes):\n",
    "            t=tauler.copy()\n",
    "\n",
    "            antact=-3\n",
    "            reward=-1\n",
    "            current_rewards = []\n",
    "            current_grads = []\n",
    "            for step in range(n_max_steps):\n",
    "                t, antact,reward, done, grads, rati = play_one_step(t, model, loss_fn,antact,reward,iteration)\n",
    "                current_rewards.append(reward)\n",
    "                current_grads.append(grads)\n",
    "                if done:\n",
    "                    break\n",
    "            if sum(current_rewards)>maxim:\n",
    "                maxim=sum(current_rewards)\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_grads.append(current_grads)\n",
    "        if i%2==0:\n",
    "            tauler=np.flip(tauler,0)\n",
    "        else:\n",
    "            tauler=np.flip(tauler,1)\n",
    "        \n",
    "    return all_rewards, all_grads, maxim, nom, rati\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XT_7CUgqf_pK"
   },
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_rate):\n",
    "    discounted = np.array(rewards)\n",
    "    for step in range(len(rewards) - 2, -1, -1):\n",
    "        discounted[step] += discounted[step + 1] * discount_rate\n",
    "    return discounted\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_rate)\n",
    "                              for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean) / reward_std\n",
    "            for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y7KDrGQlf_pL"
   },
   "outputs": [],
   "source": [
    "n_iterations = 2500\n",
    "n_episodes_per_update = 30\n",
    "n_max_steps = 30\n",
    "discount_rate = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "99FRRwF3f_pL"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = keras.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YUJMrbfKf_pL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 16)]           0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 16, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 16, 32)         320       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 53,140\n",
      "Trainable params: 52,948\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model=tf.keras.models.load_model('C:/Users/josep/Snowman/snowv1-5-f.h5')\n",
    "#model.load_weights('C:/Users/josep/Snowman/Dades/jugades/checkpoint/checkpoint')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prova():\n",
    "    nom=files[random.randint(0,len(files)-1)]\n",
    "    nom='C:/Users/josep/Snowman/Dades/alice.txt'\n",
    "    tauler=lleguir_tauler(nom,n=n,m=m)\n",
    "    print(tauler)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    sum_rewards=0\n",
    "\n",
    "    for i in range(30):\n",
    "        action2=model.predict(arreglar_taula(tauler)[np.newaxis]).squeeze()\n",
    "        action=np.argmax(action2)\n",
    "        clear_output(wait=True)\n",
    "        tauler, reward, done, a, b, sega, segb, segaa, segbb= step(tauler,action)\n",
    "        sum_rewards+=reward\n",
    "        print(action,i,sum_rewards,action2)\n",
    "        print(tauler)\n",
    "        time.sleep(1)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "S7eMDFhQf_pL",
    "outputId": "517e8796-9c99-46b4-aff0-e1bbcd934edc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "**** Iteration: 1514 mean rewards:    0.4 mov: [1015135, 1134906, 945533, 1146140] maxim: 4 nom: david-10.txt rati: 0.100  \n",
      "\r",
      "nom: david-0.txt  mean:      8.4     17.4 1242     max:     50     50 1512   \n",
      "\r",
      "nom: david-1.txt  mean:      3.8      4.8 1135     max:      0     21  433   \n",
      "\r",
      "nom: david-10.txt mean:      0.4      3.7 1244     max:      4      5 1298   \n",
      "\r",
      "nom: david-11.txt mean:     -4.4     -3.1 1137     max:      2     52  543   \n",
      "\r",
      "nom: david-12.txt mean:     -8.1     -4.3 1219     max:      0      0 1489   \n",
      "\r",
      "nom: david-13.txt mean:     11.9     19.4 1220     max:     52     52 1490   \n",
      "\r",
      "nom: david-14.txt mean:     -4.7     -3.8 1437     max:      0      0 1491   \n",
      "\r",
      "nom: david-15.txt mean:    -29.4    -26.9  979     max:     -2      0 1438   \n",
      "\r",
      "nom: david-16.txt mean:    -24.3    -20.8 1331     max:     19     21 1466   \n",
      "\r",
      "nom: david-17.txt mean:     10.2     13.2 1359     max:     21     22 1332   \n",
      "\r",
      "nom: david-18.txt mean:      7.4      9.6 1225     max:     23     23 1495   \n",
      "\r",
      "nom: david-19.txt mean:      7.0      7.0 1496     max:     21     22  686   \n",
      "\r",
      "nom: david-2.txt  mean:     13.0     13.6  741     max:     52     52 1497   \n",
      "\r",
      "nom: david-20.txt mean:     -1.2      1.3 1039     max:      4      7  661   \n",
      "\r",
      "nom: david-21.txt mean:      0.1      0.7 1283     max:      6      6 1499   \n",
      "\r",
      "nom: david-22.txt mean:     -2.1      0.9 1122     max:      6      7   96   \n",
      "\r",
      "nom: david-23.txt mean:     -8.1     -3.3 1312     max:      4      6 1339   \n",
      "\r",
      "nom: david-24.txt mean:    -15.7    -13.9  395     max:      3      4  368   \n",
      "\r",
      "nom: david-25.txt mean:    -14.4    -14.1  639     max:      5      5 1503   \n",
      "\r",
      "nom: david-26.txt mean:    -13.6    -12.4 1045     max:      4      5  451   \n",
      "\r",
      "nom: david-3.txt  mean:     12.4     13.2  749     max:      0     52 1478   \n",
      "\r",
      "nom: david-4.txt  mean:     24.5     24.5 1506     max:     51     51 1506   \n",
      "\r",
      "nom: david-5.txt  mean:     23.2     23.9 1480     max:     50     50 1507   \n",
      "\r",
      "nom: david-7.txt  mean:     11.3     14.9  887     max:      4      6 1346   \n",
      "\r",
      "nom: david-8.txt  mean:      3.5     11.1  969     max:     20     20 1509   \n",
      "\r",
      "nom: david-9.txt  mean:      8.0     10.3 1105     max:      0     20 1402   \n",
      "\r",
      "nom: david.txt    mean:     -1.1      0.0 1160     max:      4      8 1457   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10536/648559720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvar_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         mean_grads = tf.reduce_mean(\n\u001b[1;32m---> 37\u001b[1;33m             [final_reward * all_grads[episode_index][step][var_index]\n\u001b[0m\u001b[0;32m     38\u001b[0m              \u001b[1;32mfor\u001b[0m \u001b[0mepisode_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_rewards\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_final_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                  for step, final_reward in enumerate(final_rewards)], axis=0)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10536/648559720.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvar_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         mean_grads = tf.reduce_mean(\n\u001b[1;32m---> 37\u001b[1;33m             [final_reward * all_grads[episode_index][step][var_index]\n\u001b[0m\u001b[0;32m     38\u001b[0m              \u001b[1;32mfor\u001b[0m \u001b[0mepisode_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_rewards\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_final_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                  for step, final_reward in enumerate(final_rewards)], axis=0)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m   1398\u001b[0m       \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1400\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m   \u001b[1;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1708\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    528\u001b[0m   \"\"\"\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6229\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6230\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6231\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6232\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[0;32m   6233\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "estadistiques=[]\n",
    "for i in range(len(files)):\n",
    "    estadistiques.append([os.path.basename(files[i]),-2000,-2000,-1,-2000,-2000,-1])\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    if (iteration+1)%100==0:\n",
    "        prova()\n",
    "    \n",
    "    all_rewards, all_grads, maxim, nom, rati= play_multiple_episodes(n_episodes_per_update, n_max_steps, model, loss_fn,iteration)\n",
    "\n",
    "    total_rewards = sum([sum(ar) for ar in all_rewards])                   # Not shown in the book\n",
    "\n",
    "    [nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim]=estadistiques[iteration%len(files)]\n",
    "\n",
    "    actmean=total_rewards/(n_episodes_per_update*4)\n",
    "    if actmean>=maxmean:\n",
    "        maxmean=actmean\n",
    "        itmean=iteration\n",
    "    actmaxim=maxim\n",
    "    if actmaxim>=maxmaxim:\n",
    "        maxmaxim=actmaxim\n",
    "        itmaxim=iteration\n",
    "    estadistiques[iteration%len(files)]=[nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim]\n",
    "    clear_output(wait=True)\n",
    "    print(\"\\r**** Iteration: {} mean rewards: {:6.1f} mov: {} maxim: {} nom: {:12} rati: {:.3f}  \".format(iteration, total_rewards/(n_episodes_per_update*4),Mov,maxim,nom,rati), end=\"\") # Not shown\n",
    "    \n",
    "    for element in estadistiques:\n",
    "        [nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim]=element\n",
    "        print(\"\\n\\rnom: {:12} mean: {:8.1f} {:8.1f} {:4}     max: {:6} {:6} {:4}   \".format(nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim), end=\"\")\n",
    "   \n",
    "   \n",
    "    all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_rate)\n",
    "    \n",
    "    all_mean_grads = []\n",
    "    for var_index in range(len(model.trainable_variables)):\n",
    "        mean_grads = tf.reduce_mean(\n",
    "            [final_reward * all_grads[episode_index][step][var_index]\n",
    "             for episode_index, final_rewards in enumerate(all_final_rewards)\n",
    "                 for step, final_reward in enumerate(final_rewards)], axis=0)\n",
    "        all_mean_grads.append(mean_grads)\n",
    "        \n",
    "\n",
    "        \n",
    "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prova()\n",
    "model.save('snowv1-6-f.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copia de 18_reinforcement_learning.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/ageron/handson-ml2/blob/master/18_reinforcement_learning.ipynb",
     "timestamp": 1643739375886
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
