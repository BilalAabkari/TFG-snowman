{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a ref=\"C:/Users/josep/Snowman/Reforçat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" ref=\"C:/Users/josep/Snowman/Reforçat.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "o2j3RSpxf_o4"
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import glob\n",
    "\n",
    "n=8\n",
    "m=16\n",
    "\n",
    "Mov=[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/josep/Snowman/Dades/facils/\"\n",
    "\n",
    "files=glob.glob(path+\"*.txt\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intern code:\n",
    "\n",
    "- 0 : out of grid and wall (x and #)\n",
    "- 1 : small ball\n",
    "- 2 : medium ball\n",
    "- 3 : small ball on top of a medium ball\n",
    "- 4 : large ball\n",
    "- 5 : small ball on top of a large ball\n",
    "- 6 : medium ball on top of a large ball\n",
    "- 7 : small ball on top of a medium ball on top of a large ball\n",
    "- 8 : grass (')\n",
    "- 9 : snow (.)\n",
    "- 10: character with snow on the floor (p)\n",
    "- 11: character with grass on the floor (q)\n",
    "\n",
    "\n",
    "Reconpenses\n",
    "- 0 moure's sense apretar \n",
    "- 0 moure's apretant bola petita\n",
    "- 0 moure's apretant bola mitjana\n",
    "- 0 moure's apretant bola grossa\n",
    "- 100 col.locar bola mitjana sobre bola grossa\n",
    "- 500 col.locar bola petita sobre boles mitjnes i grosses\n",
    "- -1 Passar un instant \n",
    "\n",
    "Accions prohibides (-100 punts)\n",
    "- sortir de la quadricula (trepitjar pared)\n",
    "- fer sortir bola de la quadricula (trepitjar pared la bola)\n",
    "- fer 2 boles grans\n",
    "- fer dos boles mitjanes si ja tenim bola gran\n",
    "\n",
    "\n",
    "Maxim episodi=50 jugades, fins acció prohibida o col.locar tres boles be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=-20\n",
    "tonto=-20\n",
    "cami=-1\n",
    "camir=0\n",
    "cim=5\n",
    "cimbo=20\n",
    "convertir=3\n",
    "bingo=50\n",
    "\n",
    "actions=[ \n",
    "        # pared                   bola petita          bola mitjana         bola pet s mit            bola grossa           bola pet s gr         bola mit s gr             tres boles            herba                   neu              \n",
    "    [[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error]], #pared\n",
    "    [[None,None,None,error],[None,None,None,tonto],['pq',11,3,cim]       ,[None,None,None,tonto],['pq',11,5,cim]       ,[None,None,None,tonto],['pq',11,7,bingo]     ,[None,None,None,tonto],['pq',11,1,camir]     ,['pq',11,2,convertir]],  #bola petita\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],['pq',11,6,cimbo]     ,[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],['pq',11,2,camir]      ,['pq',11,4,convertir]],  #bola mitjana\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,2,1,-cim]       ,[None,2,1,-cim]],        #bola pet s mit\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],['pq',11,4,cami]      ,['pq',11,4,cami]],       #bola gran\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,4,1,-cim]       ,[None,4,2,-cim]],        #bola pet s gr\n",
    "    [[None,None,None,error],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,None,None,tonto],[None,4,2,-cimbo]     ,[None,4,4,-cimbo]],      #bola mitj s gr\n",
    "    [[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error],[None,None,None,error]], #tres boles\n",
    "    [['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,cami]   ,['pq',11,None,tonto]  ,['pq',11,None,cami]   ,['pq',11,None,cami]],    #herba\n",
    "    [['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,cami]   ,['pq',10,None,tonto]  ,['pq',10,None,cami]   ,['pq',10,None,cami]]     #neu\n",
    "] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ree=\"x#'.pq1234567\"\n",
    "reem=[0,0,8,9,10,11,1,2,3,4,5,6,7]\n",
    "def lleguir_tauler(nom,n=n,m=m):\n",
    "    f = open(nom, \"r\")\n",
    "    tauler=np.zeros((n,m),dtype=int)\n",
    "    for row,linea in enumerate(f):\n",
    "        linea=linea.rstrip('\\n\\r\\t')\n",
    "        for column,car in enumerate(linea):\n",
    "            res = ree.find(car)\n",
    "            tauler[row,column]=reem[res]\n",
    "    f.close()\n",
    "    return np.array(tauler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_step(t,reward,row,column,sega,segb,segaa,segbb):\n",
    "    bonus=2\n",
    "    if reward==cami:\n",
    "        ball=[1,2]\n",
    "        distact=distancia(t,row,column,ball)\n",
    "        distnou=distancia(t,sega,segb,ball)\n",
    "        if distnou<distact:\n",
    "            reward=cami+bonus\n",
    "    if reward==camir:\n",
    "        if t[sega,segb]==1:\n",
    "            ball=[2,6]\n",
    "        elif t[sega,segb]==2:\n",
    "            ball=[4]\n",
    "        else:\n",
    "            ball=[]\n",
    "        distact=distancia(t,row,column,ball)\n",
    "        distnou=distancia(t,sega,segb,ball)\n",
    "        if distnou<distact:\n",
    "            reward=camir+bonus\n",
    "    if reward==convertir:\n",
    "        if t[sega,segb]==2:\n",
    "            res = np.isin(t,[4,5,6])\n",
    "            res = np.array(np.where(res))\n",
    "            if np.size(res)!=0:\n",
    "                reward=error\n",
    "        else:\n",
    "            res = np.isin(t,[2,3,6])\n",
    "            res = np.array(np.where(res))\n",
    "            res2= np.isin(t,[4,5,6])\n",
    "            res2= np.array(np.where(res2))\n",
    "            if np.size(res)>0:\n",
    "                if res.shape[1]>=2 or (res.shape[1]==1 and res2.shape[1]>=1):\n",
    "                    reward=error\n",
    "    \n",
    "        \n",
    "    return reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(t,r,c,ball):\n",
    "    dist=500\n",
    "    for b in ball:\n",
    "        res = np.array(np.where(t == b))\n",
    "        if np.size(res)!=0:\n",
    "            for j in range(res.shape[1]):\n",
    "                if abs(r-res[0][j])+abs(c-res[1][j])<dist:\n",
    "                    dist=abs(r-res[0][j])+abs(c-res[1][j])\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "def step(t,action,passat): # 0 dreta, 1 baix, 2 esquerra, 3 dalt\n",
    "    snow=True\n",
    "    res = np.array(np.where(t == 10))\n",
    "    if np.size(res)==0: \n",
    "        snow=False\n",
    "        res = np.array(np.where(t == 11))\n",
    "    a=res[0][0]\n",
    "    b=res[1][0]\n",
    "    \n",
    "    inc=[[0,1,0,-1],[1,0,-1,0]]\n",
    "    seg=[a+inc[0][action],b+inc[1][action]]\n",
    "    seg2=[a+2*inc[0][action],b+2*inc[1][action]]\n",
    "\n",
    "    Mov[action]=Mov[action]+1\n",
    "    if seg2[0]<0 or seg2[0]>=8 or seg2[1]<0 or seg2[1]>=16:\n",
    "        aux=0\n",
    "    else:\n",
    "        aux=t[seg2[0],seg2[1]]\n",
    "\n",
    "    mact=actions[t[seg[0],seg[1]]][aux]\n",
    "    reward=mact[3]\n",
    "    mact=mact[:3]\n",
    "    for i,aux in enumerate(mact):\n",
    "        if aux!=None:\n",
    "            if aux=='pq':\n",
    "                if snow:\n",
    "                    f=9\n",
    "                else:\n",
    "                    f=8\n",
    "            else:\n",
    "                f=int(aux)\n",
    "\n",
    "            if i==0:\n",
    "                t[a,b]=f\n",
    "            elif i==1:\n",
    "                t[seg[0],seg[1]]=f\n",
    "            else:\n",
    "                t[seg2[0],seg2[1]]=f\n",
    "\n",
    "    if reward==cami or reward==camir: #no pot tornar a passar per el mateix lloc\n",
    "        passat[seg[0],seg[1]]+=1\n",
    "        if passat[seg[0],seg[1]]>1:\n",
    "            reward=tonto\n",
    "    else:\n",
    "        passat=np.zeros((n,m))\n",
    "    \n",
    "    if reward==bingo or reward<=tonto:\n",
    "        done=True\n",
    "    else:\n",
    "        done=False\n",
    "\n",
    "    return (t,reward,done,a,b,seg[0],seg[1],seg2[0],seg2[1],passat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arreglar_taula(t):\n",
    "    t2=t.copy()\n",
    "    res = np.array(np.where(t2 == 11))\n",
    "    if np.size(res)!=0:\n",
    "        t2[res[0][0],res[1][0]]=10\n",
    "    return t2/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rfaXj3ihf_pJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "from random import choices\n",
    "\n",
    "\n",
    "\n",
    "def play_one_step(t, model, loss_fn,iteration,passat):\n",
    "    with tf.GradientTape() as tape:\n",
    "        left_proba = tf.squeeze(model(arreglar_taula(t)[np.newaxis]))\n",
    "    \n",
    "        r=np.random.uniform()\n",
    "        rati=max((1000-iteration)/1000*0.6,0.10)\n",
    "        if r>rati:\n",
    "            action = choices(population=range(4), k=1, weights=left_proba)\n",
    "        else:\n",
    "            action = choices(population=range(4), k=1)\n",
    "       \n",
    "        y_target = np.eye(4)[action[0]]\n",
    "        loss = tf.reduce_mean(loss_fn(y_target, left_proba))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    t, reward, done, a, b, sega, segb, segaa, segbb, passat= step(t,action[0],passat)\n",
    "    reward=mod_step(t,reward,a,b,sega,segb,segaa,segbb)\n",
    "    return t,reward, done, grads, rati, passat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "IgF5UpXKf_pK"
   },
   "outputs": [],
   "source": [
    "def play_multiple_episodes(n_episodes, n_max_steps, model, loss_fn,iteration):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "\n",
    "    \n",
    "    nom=files[iteration % len(files)]\n",
    "    tauler=lleguir_tauler(nom,n=n,m=m)\n",
    "    for i in range(4):\n",
    "        maxim=-1000000\n",
    "        for episode in range(n_episodes):\n",
    "            t=tauler.copy()\n",
    "            passat=np.zeros((n,m))\n",
    "\n",
    "            antact=-3\n",
    "            reward=-1\n",
    "            current_rewards = []\n",
    "            current_grads = []\n",
    "            for step in range(n_max_steps):\n",
    "                t, reward, done, grads, rati, passat = play_one_step(t, model, loss_fn,iteration,passat)\n",
    "                current_rewards.append(reward)\n",
    "                current_grads.append(grads)\n",
    "                if done:\n",
    "                    break\n",
    "            if sum(current_rewards)>maxim:\n",
    "                maxim=sum(current_rewards)\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_grads.append(current_grads)\n",
    "        if i%2==0:\n",
    "            tauler=np.flip(tauler,0)\n",
    "        else:\n",
    "            tauler=np.flip(tauler,1)\n",
    "        \n",
    "    return all_rewards, all_grads, maxim, nom, rati\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "XT_7CUgqf_pK"
   },
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_rate):\n",
    "    discounted = np.array(rewards)\n",
    "    for step in range(len(rewards) - 2, -1, -1):\n",
    "        discounted[step] += discounted[step + 1] * discount_rate\n",
    "    return discounted\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_rate)\n",
    "                              for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean) / reward_std\n",
    "            for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Y7KDrGQlf_pL"
   },
   "outputs": [],
   "source": [
    "n_iterations = 2500\n",
    "n_episodes_per_update = 25\n",
    "n_max_steps = 50\n",
    "discount_rate = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "99FRRwF3f_pL"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = keras.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "YUJMrbfKf_pL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 16)]           0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 16, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 16, 32)         320       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 53,140\n",
      "Trainable params: 52,948\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model=tf.keras.models.load_model('C:/Users/josep/Snowman/snowv1-10-f.h5')\n",
    "#model.load_weights('C:/Users/josep/Snowman/Dades/jugades/checkpoint/checkpoint')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prova(nom=None):\n",
    "    if nom==None:\n",
    "        nom=files[random.randint(0,len(files)-1)]\n",
    "    \n",
    "    tauler=lleguir_tauler(nom,n=n,m=m)\n",
    "    print(tauler)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    sum_rewards=0\n",
    "\n",
    "    for i in range(30):\n",
    "        action2=model.predict(arreglar_taula(tauler)[np.newaxis]).squeeze()\n",
    "        action=np.argmax(action2)\n",
    "        clear_output(wait=True)\n",
    "        tauler, reward, done, a, b, sega, segb, segaa, segbb, passat= step(tauler,action,np.zeros((n,m)))\n",
    "        sum_rewards+=reward\n",
    "        print(action,i,sum_rewards,action2,done)\n",
    "        print(tauler)\n",
    "        time.sleep(5)\n",
    "        if done:\n",
    "            break\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7eMDFhQf_pL",
    "outputId": "517e8796-9c99-46b4-aff0-e1bbcd934edc",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Iteration: 1735 mean rewards:  -19.5 mov: [335143, 422878, 378948, 457216] maxim: -14 nom: david-23.txt rati: 0.100  \n",
      "nom: david-1.txt  mean:    -11.5     -6.8  840     max:    -14      3  651   \n",
      "nom: david-10.txt mean:    -11.7     -7.0 1660     max:     55     55 1723   \n",
      "nom: david-11.txt mean:    -20.9    -18.9 1325     max:    -18     52 1577   \n",
      "nom: david-12.txt mean:    -22.0    -21.0 1557     max:    -20     50 1704   \n",
      "nom: david-14.txt mean:    -22.1    -21.4 1495     max:    -20    -20 1726   \n",
      "nom: david-15.txt mean:    -26.9    -24.5  236     max:    -20    -20 1727   \n",
      "nom: david-16.txt mean:    -19.9    -17.1 1581     max:      0      1 1644   \n",
      "nom: david-17.txt mean:     -4.8     -2.3 1561     max:      2      2 1729   \n",
      "nom: david-18.txt mean:    -12.9    -10.5 1667     max:    -13      4 1667   \n",
      "nom: david-19.txt mean:     -6.1     -1.5 1626     max:      0      2 1689   \n",
      "nom: david-20.txt mean:    -20.0    -15.8 1123     max:    -13    -11  199   \n",
      "nom: david-21.txt mean:    -15.2    -14.8 1208     max:    -12    -12 1733   \n",
      "nom: david-22.txt mean:    -16.3    -14.4 1146     max:    -13    -12 1692   \n",
      "nom: david-23.txt mean:    -19.5    -17.8 1042     max:    -14    -13  895   \n",
      "nom: david-24.txt mean:    -22.2    -20.1 1673     max:    -17    -11 1253   \n",
      "nom: david-25.txt mean:    -19.7    -19.1 1590     max:    -15    -11  582   \n",
      "nom: david-26.txt mean:    -19.1    -17.9 1696     max:    -14    -11  898   \n",
      "nom: david-7.txt  mean:     -8.2     -4.5 1424     max:     56     56 1718   \n",
      "nom: david-8.txt  mean:     -5.0     -2.5 1467     max:      1      1 1719   \n",
      "nom: david-9.txt  mean:    -15.2    -12.8 1279     max:     -1      0 1678   \n",
      "nom: david.txt    mean:    -15.3    -15.3 1721     max:    -10    -10 1721   "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "estadistiques=[]\n",
    "for i in range(len(files)):\n",
    "    estadistiques.append([os.path.basename(files[i]),-2000,-2000,-1,-2000,-2000,-1])\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    if (iteration+1)%100==0:\n",
    "        prova(nom='C:/Users/josep/Snowman/Dades/facils/david-11.txt')\n",
    "    \n",
    "    all_rewards, all_grads, maxim, nom, rati= play_multiple_episodes(n_episodes_per_update, n_max_steps, model, loss_fn,iteration)\n",
    "\n",
    "    total_rewards = sum([sum(ar) for ar in all_rewards])                   # Not shown in the book\n",
    "\n",
    "    [nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim]=estadistiques[iteration%len(files)]\n",
    "\n",
    "    actmean=total_rewards/(n_episodes_per_update*4)\n",
    "    if actmean>=maxmean:\n",
    "        maxmean=actmean\n",
    "        itmean=iteration\n",
    "    actmaxim=maxim\n",
    "    if actmaxim>=maxmaxim:\n",
    "        maxmaxim=actmaxim\n",
    "        itmaxim=iteration\n",
    "    estadistiques[iteration%len(files)]=[nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim]\n",
    "    clear_output(wait=True)\n",
    "    print(\"\\r**** Iteration: {} mean rewards: {:6.1f} mov: {} maxim: {} nom: {:12} rati: {:.3f}  \".format(iteration, total_rewards/(n_episodes_per_update*4),Mov,maxim,nom,rati), end=\"\") # Not shown\n",
    "    \n",
    "    for element in estadistiques:\n",
    "        [nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim]=element\n",
    "        print(\"\\n\\rnom: {:12} mean: {:8.1f} {:8.1f} {:4}     max: {:6} {:6} {:4}   \".format(nom,actmean,maxmean,itmean,actmaxim,maxmaxim,itmaxim), end=\"\")\n",
    "   \n",
    "   \n",
    "    all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_rate)\n",
    "    \n",
    "    all_mean_grads = []\n",
    "    for var_index in range(len(model.trainable_variables)):\n",
    "        mean_grads = tf.reduce_mean(\n",
    "            [final_reward * all_grads[episode_index][step][var_index]\n",
    "             for episode_index, final_rewards in enumerate(all_final_rewards)\n",
    "                 for step, final_reward in enumerate(final_rewards)], axis=0)\n",
    "        all_mean_grads.append(mean_grads)\n",
    "        \n",
    "\n",
    "        \n",
    "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prova(nom='C:/Users/josep/Snowman/Dades/facils/david-18.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.save('snowv1-11-f.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copia de 18_reinforcement_learning.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/ageron/handson-ml2/blob/master/18_reinforcement_learning.ipynb",
     "timestamp": 1643739375886
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
